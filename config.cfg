[OpenAI]
# Optional. Set these if you are testing OpenAI models.
organization_id = 
api_key = 

[Huggingface]
# Optional. This allows the script to download gated models.
access_token = 

[Results upload]
# Optional. Set this to allow uploading of results to a google sheets spreadsheet.
# Note: this feature requires extra configuration (see README).
google_spreadsheet_url = 

[Options]
# Set to true or false
trust_remote_code = false

[Oobabooga config]
# e.g. /home/[user]/text-generation-webui/start_linux.sh
ooba_launch_script = 

# This is where ooba models will be downloaded to.
# - defaults to [ooba install]/models
models_dir = 

# Specify any additional ooba launch params (this can be overridden on a per-model basis).
# e.g.:
# --auto-devices --loader llama.cpp
ooba_params_global = 

[Benchmarks to run]
# Define benchmarks in the following format:
# run_id, prompt_type, model_path, lora_path, quantization, n_iterations, inference_engine, ooba_params

# Details:
# - run_id: A string to identify the benchmark run
# - prompt_type: The prompt format (e.g., openai_api, chatml, etc.)
# - model_path: Huggingface model ID, local path, or OpenAI model name
# - lora_path: Path to local lora adapter (optional)
# - quantization: Using bitsandbytes package (8bit, 4bit, None)
# - n_iterations: Number of benchmark iterations (final score will be an average)
# - inference_engine: Set this to transformers, openai or oobabooga.
# - ooba_params: Any additional ooba params for loading this model (overrides the global setting above)

# Examples:
# myrun1, Qwen, Qwen/Qwen-14B-Chat, /path/to/local/lora/adapter, 8bit, 3, transformers, ,
# myrun2, openai_api, gpt-4-0613, , , 1, openai, 
# myrun3, Alpaca, microsoft/phi-1, , None, 1, oobabooga, 
